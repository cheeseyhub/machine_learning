# -*- coding: utf-8 -*-
"""notebook (2).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1P46KQb6NZKvxz1aOwxkmAG8Sn6ol-GGr

## Importing Libraries
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.tree import DecisionTreeRegressor
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, root_mean_squared_error

"""## Load and Inspect the Data"""

df = pd.read_csv('insurance.csv')
df.head()

df.shape

df.info()

df.describe()

"""## Exploratory Data Analysis (EDA)"""

# Histogram for continuous features
df.hist(bins=30, figsize=(12, 8))
plt.tight_layout()
plt.show()

for col in ['sex', 'smoker', 'region']:
    plt.figure(figsize=(10,5))
    sns.boxplot(x=col, y='charges', data=df)
    plt.title(f'{col} vs charges')
    plt.show()

sns.scatterplot(x='bmi', y='charges', hue='smoker', data=df)

"""### Insights:
- Smokers with high bmi are paying the most
"""

# Correlation Matrix
plt.figure(figsize=(8, 6))
sns.heatmap(df.corr(numeric_only=True), annot=True)
plt.title("Correlation Matrix")
plt.show()

"""# DATA PREPROCESSING

## Applying log transformation to Charges as it is right skewed
"""

df['charges'] = np.log1p(df['charges'])
sns.histplot(x='charges', data=df, kde=True)

X = df.drop('charges', axis=1)
y = df['charges']

"""## Checking missing values"""

X.isna().sum()

"""No missing vals ✔️

## Splitting Data
"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""## Encoding & Scaling"""

# Separate categorical and numerical columns
cat_cols = ['sex', 'smoker', 'region']
num_cols = ['age', 'bmi', 'children']

# Preprocessor
preprocessor = ColumnTransformer([
    ('onehot', OneHotEncoder(drop='first'), cat_cols),
    ('scaler', StandardScaler(), num_cols)
])

"""## Building Pipeline"""

pipeline1 = Pipeline([
    ('preprocess', preprocessor),
    ('model', DecisionTreeRegressor())
])

"""## Train the Model"""

pipeline1.fit(X_train, y_train)

"""## Make Predictions and Evaluate"""

y_pred = pipeline1.predict(X_test)

r2 = r2_score(y_test, y_pred)
rmse = root_mean_squared_error(y_test, y_pred)

print("R² Score:", r2)
print("RMSE:", rmse)

"""## Visualization – Actual vs Predicted"""

plt.figure(figsize=(8,6))
sns.scatterplot(x=y_test, y=y_pred, alpha=0.6)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')  # Ideal line
plt.xlabel("Actual Charges")
plt.ylabel("Predicted Charges")
plt.title("Actual vs Predicted Charges")
plt.grid(True)
plt.tight_layout()
plt.show()

pipeline2 = Pipeline([
    ('preprocess', preprocessor),
    ('model', DecisionTreeRegressor())
])

pipeline2.fit(X_train,y_train)

treeY_predict =pipeline2.predict(X_test)

r2ScoreForDecisionTreeRegressor = r2_score(treeY_predict,y_pred);
rmseOfDecisionTreeRegressor = root_mean_squared_error(treeY_predict,y_pred)
print(f"R^2 {r2ScoreForDecisionTreeRegressor}");
print(f"RMSE {rmseOfDecisionTreeRegressor}")

plt.figure(figsize=(8,6))
sns.scatterplot(x=y_test, y=treeY_predict, alpha=0.6)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')  # Ideal line
plt.xlabel("Actual Charges")
plt.ylabel("Predicted Charges")
plt.title("Actual vs Predicted Charges")
plt.grid(True)
plt.tight_layout()
plt.show()